# Crawler

Crawler реализуется в виде консольной утилиты с тремя командами: update, download, clean.

## Команда update

Команда update позволяет найти и сохранить ссылки на еще не скачанные статьи, опубликованные в определенный промежуток времени. Логика команды основана на переборе ссылок (ссылка на статью имеет вид "http://www.engadget.com/2016/02/26/mit-wave-warning-system/", дата публикации извлекается с помощью регулярных выражений). 

Ключи команды update:

        --help - Для получения инструкции к команде

        --from - Задает начальную дату публикации искомых статей

        --to - Задает конечную дату публикации статей

        --print - Печатает найденные ссылки

## Команда download

Команда download по полученному в результате работы команды update списку ссылок или по списку ссылок, заданному как параметр команды, скачивает html-код страниц, находящихся по данным ссылкам. Страницы сохраняются в формате html, имя файла - название статьи (ссылка на статью имеет вид "http://www.engadget.com/2016/02/26/mit-wave-warning-system/", из нее достаточно просто достать название статьи).

Ключи команды download:

        --help - инструкция

        --all - скачивание всех статей из списка статей, полученных update

        [urls] - скачивание только определенных статей

        -t - количество потоков

## Команда clean

Команда clean очищает html-код статьи от "мусора", оставляя только название и текст. С помощью HTMLParser из библиотеки html происходит поиск тегов, в которых содержатся заголовок и текст статьи, их содержимое сохраняется в новый txt файл. Также clean обновляет информацию о количестве очищенных файлов в файле info.

Ключи команды clean:

        --help - инструкция

        --all - очистка всех загруженных, но не очищенных статей

        [urls] - очистка определенной статьи


# Оценка статей

Консольная утилита mark позволяет ставить оценки новым, еще не оцененным статьям.

# Классификация статей

ML_notebook - ipython3 Notebook,с реализованным линейным классификатором на основе модели мешка слов, также применяется процедура кросс-валидации.

# Используемые технологии

Библитотеки sklearn, nltk, re, urllib, html, io, argparse, sys, os, collections, traceback, logging, random, datetime.
